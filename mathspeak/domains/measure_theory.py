#!/usr/bin/env python3
"""
Measure Theory Domain Processor for Mathematical Text-to-Speech
==============================================================

Complete processor for measure theory notation including:
- Sigma-algebras and measurable spaces
- Measures and outer measures
- Integration theory (Lebesgue integral)
- Lp spaces and function spaces
- Convergence theorems
- Product measures and Fubini's theorem
- Radon-Nikodym theorem and derivatives
- Probability measure connections

This processor handles ALL measure theory notation with professor-quality pronunciation.
"""

import re
import logging
from typing import Dict, List, Tuple, Optional, Union, Callable, Any
from dataclasses import dataclass
from collections import OrderedDict
from enum import Enum

logger = logging.getLogger(__name__)

# ===========================
# Measure Theory Context Types
# ===========================

class MeasureTheoryContext(Enum):
    """Specific measure theory contexts for fine-grained processing"""
    SIGMA_ALGEBRAS = "sigma_algebras"
    MEASURES = "measures"
    INTEGRATION = "integration"
    LP_SPACES = "lp_spaces"
    CONVERGENCE = "convergence"
    PRODUCT_MEASURES = "product_measures"
    RADON_NIKODYM = "radon_nikodym"
    GENERAL = "general"

@dataclass
class MeasureTheoryTerm:
    """Represents a measure theory term with pronunciation hints"""
    latex: str
    spoken: str
    context: MeasureTheoryContext
    emphasis: bool = False
    add_article: bool = True

# ===========================
# Comprehensive Measure Theory Vocabulary
# ===========================

class MeasureTheoryVocabulary:
    """Complete measure theory vocabulary with natural pronunciations"""
    
    def __init__(self):
        self.terms = self._build_vocabulary()
        self.patterns = self._build_patterns()
        self.compiled_patterns = self._compile_patterns()
    
    def _escape_for_both_backslashes(self, pattern: str) -> str:
        """Convert a pattern to match both single and double backslash versions"""
        import re as regex
        
        def replace_command(match):
            cmd = match.group(0)
            if cmd.startswith(r'\\'):
                cmd_name = cmd[2:]
            else:
                return cmd
            
            return r'(?:\\\\|\\)' + regex.escape(cmd_name)
        
        pattern = regex.sub(r'\\\\[a-zA-Z]+', replace_command, pattern)
        return pattern
        
    def _build_vocabulary(self) -> Dict[str, Union[str, Callable]]:
        """Build comprehensive measure theory vocabulary"""
        vocab = {}
        
        # ===== SIGMA-ALGEBRAS AND MEASURABLE SPACES =====
        
        vocab.update({
            r'\\mathcal{A}': 'the sigma-algebra script A',
            r'\\mathcal{B}': 'the sigma-algebra script B',
            r'\\mathcal{F}': 'the sigma-algebra script F',
            r'\\mathcal{M}': 'the sigma-algebra script M',
            r'\\sigma\\(\\mathcal{C}\\)': 'the sigma-algebra generated by script C',
            r'\\sigma\\(([^)]+)\\)': lambda m: f"the sigma-algebra generated by {self._process_nested(m.group(1))}",
            r'\\mathcal{B}\\(\\mathbb{R}\\)': 'the Borel sigma-algebra on the reals',
            r'\\mathcal{B}\\(\\mathbb{R}^n\\)': 'the Borel sigma-algebra on R n',
            r'\\mathcal{B}\\(([^)]+)\\)': lambda m: f"the Borel sigma-algebra on {self._process_nested(m.group(1))}",
            r'\\mathcal{L}': 'the Lebesgue sigma-algebra',
            r'\\mathcal{P}\\(([^)]+)\\)': lambda m: f"the power set of {self._process_nested(m.group(1))}",
            r'\\mathcal{N}': 'the null sets',
            r'\\text{measurable}': 'measurable',
            r'\\mathcal{A}/\\mathcal{B}\\text{-measurable}': 'script A over script B measurable',
        })
        
        # ===== MEASURES =====
        
        vocab.update({
            r'\\mu': 'mu',
            r'\\nu': 'nu',
            r'\\lambda': 'lambda',
            r'\\rho': 'rho',
            r'\\mu\\(([^)]+)\\)': lambda m: f"mu of {self._process_nested(m.group(1))}",
            r'\\nu\\(([^)]+)\\)': lambda m: f"nu of {self._process_nested(m.group(1))}",
            r'\\lambda\\(([^)]+)\\)': lambda m: f"lambda of {self._process_nested(m.group(1))}",
            r'm\\(([^)]+)\\)': lambda m: f"the measure of {self._process_nested(m.group(1))}",
            r'\\text{Leb}\\(([^)]+)\\)': lambda m: f"the Lebesgue measure of {self._process_nested(m.group(1))}",
            r'\\mu^\\*': 'mu star',
            r'\\mu_\\*': 'mu star',
            r'\\text{outer measure}': 'outer measure',
            r'\\text{Hausdorff measure}': 'Hausdorff measure',
            r'\\mathcal{H}^s': 'Hausdorff s-measure',
            r'\\mathcal{H}^([0-9]+)': lambda m: f"Hausdorff {m.group(1)}-measure",
            r'\\text{counting measure}': 'counting measure',
            r'\\text{Dirac measure}': 'Dirac measure',
            r'\\delta_x': 'the Dirac delta at x',
            r'\\delta_([a-z])': lambda m: f"the Dirac delta at {m.group(1)}",
        })
        
        # ===== MEASURE PROPERTIES =====
        
        vocab.update({
            r'\\text{finite measure}': 'finite measure',
            r'\\text{sigma-finite}': 'sigma-finite',
            r'\\text{probability measure}': 'probability measure',
            r'\\text{signed measure}': 'signed measure',
            r'\\text{complex measure}': 'complex measure',
            r'\\text{positive measure}': 'positive measure',
            r'\\text{regular measure}': 'regular measure',
            r'\\text{Radon measure}': 'Radon measure',
            r'\\text{absolutely continuous}': 'absolutely continuous',
            r'\\text{singular}': 'singular',
            r'\\text{mutually singular}': 'mutually singular',
            r'\\mu \\ll \\nu': 'mu is absolutely continuous with respect to nu',
            r'\\mu \\perp \\nu': 'mu is singular with respect to nu',
            r'\\text{total variation}': 'total variation',
            r'|\\mu|': 'the total variation of mu',
        })
        
        # ===== INTEGRATION =====
        
        vocab.update({
            r'\\int ([^\\s]+) d\\mu': lambda m: f"the integral of {self._process_nested(m.group(1))} with respect to mu",
            r'\\int ([^\\s]+) d\\nu': lambda m: f"the integral of {self._process_nested(m.group(1))} with respect to nu",
            r'\\int ([^\\s]+) dm': lambda m: f"the integral of {self._process_nested(m.group(1))} with respect to m",
            r'\\int_([^\\s]+) ([^\\s]+) d\\mu': lambda m: f"the integral over {self._process_nested(m.group(1))} of {self._process_nested(m.group(2))} with respect to mu",
            r'\\int_X ([^\\s]+) d\\mu': lambda m: f"the integral over X of {self._process_nested(m.group(1))} with respect to mu",
            r'\\int f \\, d\\mu': 'the integral of f with respect to mu',
            r'\\int_E f \\, d\\mu': 'the integral over E of f with respect to mu',
            r'\\int ([^\\s]+) \\, dx': lambda m: f"the Lebesgue integral of {self._process_nested(m.group(1))} with respect to x",
            r'\\text{Lebesgue integral}': 'Lebesgue integral',
            r'\\text{Riemann integral}': 'Riemann integral',
            r'\\text{simple function}': 'simple function',
            r'\\text{measurable function}': 'measurable function',
            r'\\text{integrable}': 'integrable',
            r'\\text{Lebesgue integrable}': 'Lebesgue integrable',
        })
        
        # ===== LP SPACES =====
        
        vocab.update({
            r'L^p\\(([^)]+)\\)': lambda m: f"L p space on {self._process_nested(m.group(1))}",
            r'L^([0-9]+)\\(([^)]+)\\)': lambda m: f"L {m.group(1)} space on {self._process_nested(m.group(2))}",
            r'L^p\\(([^,]+),([^)]+)\\)': lambda m: f"L p space on {self._process_nested(m.group(1))} with measure {self._process_nested(m.group(2))}",
            r'L^\\infty\\(([^)]+)\\)': lambda m: f"L infinity space on {self._process_nested(m.group(1))}",
            r'L^p\\(X,\\mu\\)': 'L p space on X with measure mu',
            r'L^1\\(X,\\mu\\)': 'L 1 space on X with measure mu',
            r'L^2\\(X,\\mu\\)': 'L 2 space on X with measure mu',
            r'\\|f\\|_p': 'the L p norm of f',
            r'\\|f\\|_([0-9]+)': lambda m: f"the L {m.group(1)} norm of f",
            r'\\|f\\|_\\infty': 'the L infinity norm of f',
            r'\\|f\\|_{L^p}': 'the L p norm of f',
            r'\\|f\\|_{L^([0-9]+)}': lambda m: f"the L {m.group(1)} norm of f",
            r'\\|f\\|_{L^\\infty}': 'the L infinity norm of f',
            r'\\text{esssup}': 'essential supremum',
            r'\\text{ess sup}': 'essential supremum',
            r'\\text{essinf}': 'essential infimum',
            r'\\text{ess inf}': 'essential infimum',
        })
        
        # ===== CONVERGENCE THEOREMS =====
        
        vocab.update({
            r'\\text{Monotone Convergence Theorem}': 'the Monotone Convergence Theorem',
            r'\\text{MCT}': 'the Monotone Convergence Theorem',
            r'\\text{Dominated Convergence Theorem}': 'the Dominated Convergence Theorem',
            r'\\text{DCT}': 'the Dominated Convergence Theorem',
            r'\\text{Fatou\'s Lemma}': 'Fatou\'s Lemma',
            r'\\text{Lebesgue\'s Dominated Convergence}': 'Lebesgue\'s Dominated Convergence Theorem',
            r'\\text{pointwise convergence}': 'pointwise convergence',
            r'\\text{uniform convergence}': 'uniform convergence',
            r'\\text{convergence in measure}': 'convergence in measure',
            r'\\text{almost everywhere convergence}': 'almost everywhere convergence',
            r'\\text{a.e. convergence}': 'almost everywhere convergence',
            r'\\text{convergence in } L^p': 'convergence in L p',
            r'\\text{weak convergence}': 'weak convergence',
            r'\\text{weak* convergence}': 'weak star convergence',
        })
        
        # ===== PRODUCT MEASURES =====
        
        vocab.update({
            r'\\mu \\times \\nu': 'mu cross nu',
            r'\\text{product measure}': 'product measure',
            r'\\text{Fubini\'s theorem}': 'Fubini\'s theorem',
            r'\\text{Tonelli\'s theorem}': 'Tonelli\'s theorem',
            r'\\text{Fubini-Tonelli}': 'the Fubini-Tonelli theorem',
            r'\\iint f\\(x,y\\) \\, d\\mu\\(x\\) \\, d\\nu\\(y\\)': 'the double integral of f of x comma y with respect to mu of x and nu of y',
            r'\\int \\int f\\(x,y\\) \\, dy \\, dx': 'the iterated integral of f of x comma y d y d x',
            r'\\int \\int f\\(x,y\\) \\, dx \\, dy': 'the iterated integral of f of x comma y d x d y',
        })
        
        # ===== RADON-NIKODYM AND DERIVATIVES =====
        
        vocab.update({
            r'\\text{Radon-Nikodym theorem}': 'the Radon-Nikodym theorem',
            r'\\text{Radon-Nikodym derivative}': 'Radon-Nikodym derivative',
            r'\\frac{d\\mu}{d\\nu}': 'the Radon-Nikodym derivative of mu with respect to nu',
            r'\\frac{d\\mu}{d\\lambda}': 'the Radon-Nikodym derivative of mu with respect to lambda',
            r'\\text{density}': 'density',
            r'\\text{Lebesgue decomposition}': 'Lebesgue decomposition',
            r'\\text{Jordan decomposition}': 'Jordan decomposition',
            r'\\text{Hahn decomposition}': 'Hahn decomposition',
            r'\\mu = \\mu_{ac} + \\mu_s': 'mu equals mu absolute continuous plus mu singular',
            r'\\text{positive part}': 'positive part',
            r'\\text{negative part}': 'negative part',
            r'\\mu^+': 'mu positive',
            r'\\mu^-': 'mu negative',
        })
        
        # ===== SET OPERATIONS AND NOTATION =====
        
        vocab.update({
            r'\\limsup_{n \\to \\infty} A_n': 'the limit superior of A sub n',
            r'\\liminf_{n \\to \\infty} A_n': 'the limit inferior of A sub n',
            r'\\bigcup_{n=1}^\\infty A_n': 'the union from n equals 1 to infinity of A sub n',
            r'\\bigcap_{n=1}^\\infty A_n': 'the intersection from n equals 1 to infinity of A sub n',
            r'\\bigsqcup_{n=1}^\\infty A_n': 'the disjoint union from n equals 1 to infinity of A sub n',
            r'A \\triangle B': 'A symmetric difference B',
            r'A \\Delta B': 'A symmetric difference B',
            r'A^c': 'A complement',
            r'A \\setminus B': 'A minus B',
            r'\\text{indicator function}': 'indicator function',
            r'\\mathbf{1}_A': 'the indicator function of A',
            r'\\mathbf{1}_([A-Z])': lambda m: f"the indicator function of {m.group(1)}",
            r'\\chi_A': 'the characteristic function of A',
            r'\\chi_([A-Z])': lambda m: f"the characteristic function of {m.group(1)}",
        })
        
        # ===== SPECIAL SETS AND SPACES =====
        
        vocab.update({
            r'\\text{null set}': 'null set',
            r'\\text{negligible set}': 'negligible set',
            r'\\text{almost everywhere}': 'almost everywhere',
            r'\\text{a.e.}': 'almost everywhere',
            r'\\text{almost surely}': 'almost surely',
            r'\\text{a.s.}': 'almost surely',
            r'\\text{support}': 'support',
            r'\\text{supp}\\(f\\)': 'the support of f',
            r'\\text{supp}\\(\\mu\\)': 'the support of mu',
            r'\\text{atoms}': 'atoms',
            r'\\text{atomic measure}': 'atomic measure',
            r'\\text{non-atomic measure}': 'non-atomic measure',
            r'\\text{purely atomic}': 'purely atomic',
            r'\\text{diffuse measure}': 'diffuse measure',
        })
        
        # ===== MAXIMAL FUNCTIONS AND HARDY-LITTLEWOOD =====
        
        vocab.update({
            r'\\text{maximal function}': 'maximal function',
            r'\\text{Hardy-Littlewood maximal function}': 'Hardy-Littlewood maximal function',
            r'Mf': 'the maximal function of f',
            r'M([f-h])': lambda m: f"the maximal function of {m.group(1)}",
            r'\\text{covering lemma}': 'covering lemma',
            r'\\text{Vitali covering}': 'Vitali covering',
            r'\\text{Besicovitch covering}': 'Besicovitch covering',
        })
        
        # ===== INEQUALITIES =====
        
        vocab.update({
            r'\\text{Hölder\'s inequality}': 'Hölder\'s inequality',
            r'\\text{Minkowski\'s inequality}': 'Minkowski\'s inequality',
            r'\\text{Jensen\'s inequality}': 'Jensen\'s inequality',
            r'\\text{Markov\'s inequality}': 'Markov\'s inequality',
            r'\\text{Chebyshev\'s inequality}': 'Chebyshev\'s inequality',
            r'\\text{Cauchy-Schwarz inequality}': 'Cauchy-Schwarz inequality',
            r'\\text{triangle inequality}': 'triangle inequality',
        })
        
        return vocab
    
    def _build_patterns(self) -> List[Tuple[str, Union[str, Callable]]]:
        """Build pattern-based replacements"""
        patterns = [
            # Sigma-algebra definitions
            (r'([A-Z]) \\text{ is a } \\sigma\\text{-algebra}',
             lambda m: f'{m.group(1)} is a sigma-algebra'),
            (r'\\mathcal{A} \\text{ is closed under countable unions}',
             'script A is closed under countable unions'),
            (r'\\mathcal{A} \\text{ is closed under complements}',
             'script A is closed under complements'),
            
            # Measure properties
            (r'\\mu \\text{ is a measure on } \\(([^,]+),([^)]+)\\)',
             lambda m: f'mu is a measure on the measurable space {self._process_nested(m.group(1))} comma {self._process_nested(m.group(2))}'),
            (r'\\mu\\(\\emptyset\\) = 0',
             'mu of the empty set equals zero'),
            (r'\\mu\\(\\bigcup_{i=1}^\\infty A_i\\) = \\sum_{i=1}^\\infty \\mu\\(A_i\\)',
             'mu of the union from i equals 1 to infinity of A sub i equals the sum from i equals 1 to infinity of mu of A sub i'),
            
            # Measurability
            (r'f \\text{ is } \\mathcal{A}/\\mathcal{B}\\text{-measurable}',
             'f is script A over script B measurable'),
            (r'f^{-1}\\(B\\) \\in \\mathcal{A}',
             'f inverse of B is in script A'),
            (r'\\{x : f\\(x\\) > a\\} \\in \\mathcal{A}',
             'the set of x such that f of x is greater than a is in script A'),
            
            # Integration definitions
            (r'\\int f \\, d\\mu = \\lim_{n \\to \\infty} \\int s_n \\, d\\mu',
             'the integral of f with respect to mu equals the limit as n approaches infinity of the integral of s sub n with respect to mu'),
            (r'\\int \\sum_{i=1}^n a_i \\mathbf{1}_{A_i} \\, d\\mu = \\sum_{i=1}^n a_i \\mu\\(A_i\\)',
             'the integral of the sum from i equals 1 to n of a sub i times the indicator function of A sub i with respect to mu equals the sum from i equals 1 to n of a sub i times mu of A sub i'),
            
            # Lp norms
            (r'\\|f\\|_p = \\left\\(\\int |f|^p \\, d\\mu\\right\\)^{1/p}',
             'the L p norm of f equals the p-th root of the integral of the absolute value of f to the p with respect to mu'),
            (r'\\|f\\|_\\infty = \\text{esssup} |f|',
             'the L infinity norm of f equals the essential supremum of the absolute value of f'),
            
            # Convergence statements
            (r'f_n \\to f \\text{ a.e.}',
             'f sub n converges to f almost everywhere'),
            (r'f_n \\to f \\text{ in measure}',
             'f sub n converges to f in measure'),
            (r'f_n \\to f \\text{ in } L^p',
             'f sub n converges to f in L p'),
            (r'\\|f_n - f\\|_p \\to 0',
             'the L p norm of f sub n minus f converges to zero'),
            
            # Dominated convergence
            (r'\\text{If } |f_n| \\leq g \\text{ and } f_n \\to f \\text{ a.e., then } \\int f_n \\, d\\mu \\to \\int f \\, d\\mu',
             'If the absolute value of f sub n is less than or equal to g and f sub n converges to f almost everywhere, then the integral of f sub n with respect to mu converges to the integral of f with respect to mu'),
            
            # Product measures
            (r'\\int \\int f\\(x,y\\) \\, d\\mu\\(x\\) \\, d\\nu\\(y\\) = \\int \\int f\\(x,y\\) \\, d\\nu\\(y\\) \\, d\\mu\\(x\\)',
             'the iterated integral of f of x comma y with respect to mu of x and nu of y equals the iterated integral of f of x comma y with respect to nu of y and mu of x'),
            
            # Radon-Nikodym
            (r'\\text{If } \\mu \\ll \\nu \\text{ and } \\nu \\text{ is } \\sigma\\text{-finite, then } \\exists h \\text{ such that } d\\mu = h \\, d\\nu',
             'If mu is absolutely continuous with respect to nu and nu is sigma-finite, then there exists h such that d mu equals h d nu'),
        ]
        
        return patterns
    
    def _compile_patterns(self) -> List[Tuple[re.Pattern, Union[str, Callable]]]:
        """Compile patterns for efficiency"""
        compiled = []
        
        # Compile vocabulary patterns
        for pattern, replacement in self.terms.items():
            try:
                if r'\\' in pattern:
                    flexible_pattern = self._escape_for_both_backslashes(pattern)
                    compiled.append((re.compile(flexible_pattern), replacement))
                else:
                    compiled.append((re.compile(pattern), replacement))
            except re.error as e:
                logger.warning(f"Failed to compile pattern {pattern}: {e}")
        
        # Compile larger patterns
        for pattern, replacement in self.patterns:
            try:
                if r'\\' in pattern:
                    flexible_pattern = self._escape_for_both_backslashes(pattern)
                    compiled.append((re.compile(flexible_pattern), replacement))
                else:
                    compiled.append((re.compile(pattern), replacement))
            except re.error as e:
                logger.warning(f"Failed to compile pattern {pattern}: {e}")
        
        return compiled
    
    def _process_nested(self, content: str) -> str:
        """Process nested mathematical content"""
        content = content.strip()
        
        # Handle common nested patterns
        replacements = [
            (r'\\mathbb{R}', 'R'),
            (r'\\mathbb{C}', 'C'),
            (r'\\mathbb{Z}', 'Z'),
            (r'\\mathbb{Q}', 'Q'),
            (r'\\mathbb{N}', 'N'),
            (r'\\mathcal{([A-Z])}', r'script \1'),
            (r'_([0-9])', r' sub \1'),
            (r'\^([0-9])', r' to the \1'),
            (r'\\infty', 'infinity'),
            (r'\\emptyset', 'the empty set'),
        ]
        
        for pattern, replacement in replacements:
            content = re.sub(pattern, replacement, content)
        
        return content

# ===========================
# Main Measure Theory Processor
# ===========================

class MeasureTheoryProcessor:
    """Main processor for measure theory domain"""
    
    def __init__(self):
        self.vocabulary = MeasureTheoryVocabulary()
        self.context = MeasureTheoryContext.GENERAL
        
        # Special handling rules
        self.special_rules = {
            'emphasize_theorems': True,
            'clarify_measures': True,
            'expand_integrals': True,
        }
        
        logger.info("Measure theory processor initialized with complete vocabulary")
    
    def detect_subcontext(self, text: str) -> MeasureTheoryContext:
        """Detect specific measure theory subcontext"""
        text_lower = text.lower()
        
        # Check for sigma-algebras
        if any(term in text_lower for term in ['sigma-algebra', 'measurable space', 'borel']):
            return MeasureTheoryContext.SIGMA_ALGEBRAS
        
        # Check for measures
        if any(term in text_lower for term in ['measure', 'outer measure', 'lebesgue measure']):
            return MeasureTheoryContext.MEASURES
        
        # Check for integration
        if any(term in text_lower for term in ['integral', 'integrate', 'lebesgue integral']):
            return MeasureTheoryContext.INTEGRATION
        
        # Check for Lp spaces
        if any(term in text_lower for term in ['lp space', 'banach space', 'hilbert']):
            return MeasureTheoryContext.LP_SPACES
        
        # Check for convergence
        if any(term in text_lower for term in ['convergence', 'dominated', 'monotone']):
            return MeasureTheoryContext.CONVERGENCE
        
        # Check for product measures
        if any(term in text_lower for term in ['product measure', 'fubini', 'tonelli']):
            return MeasureTheoryContext.PRODUCT_MEASURES
        
        # Check for Radon-Nikodym
        if any(term in text_lower for term in ['radon-nikodym', 'derivative', 'density']):
            return MeasureTheoryContext.RADON_NIKODYM
        
        return MeasureTheoryContext.GENERAL
    
    def process(self, text: str) -> str:
        """Process measure theory text with complete notation handling"""
        # Detect subcontext
        self.context = self.detect_subcontext(text)
        logger.debug(f"Measure theory subcontext: {self.context.value}")
        
        # Pre-process for common patterns
        text = self._preprocess(text)
        
        # Apply vocabulary replacements
        text = self._apply_vocabulary(text)
        
        # Apply special measure theory rules
        text = self._apply_special_rules(text)
        
        # Post-process for clarity
        text = self._postprocess(text)
        
        return text
    
    def _preprocess(self, text: str) -> str:
        """Pre-process measure theory text"""
        # Normalize common variations
        normalizations = [
            (r'\\sigma\\text{-algebra}', 'sigma-algebra'),
            (r'\\sigma\\text{-finite}', 'sigma-finite'),
            (r'\\text{a\\.e\\.}', 'almost everywhere'),
            (r'\\text{a\\.s\\.}', 'almost surely'),
            (r'meas\\(', 'the measure of '),
            (r'Leb\\(', 'the Lebesgue measure of '),
        ]
        
        for pattern, replacement in normalizations:
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text
    
    def _apply_vocabulary(self, text: str) -> str:
        """Apply measure theory vocabulary replacements"""
        # Sort patterns by length to handle longer patterns first
        sorted_patterns = sorted(self.vocabulary.compiled_patterns, 
                               key=lambda x: len(x[0].pattern), 
                               reverse=True)
        
        for pattern, replacement in sorted_patterns:
            if callable(replacement):
                text = pattern.sub(replacement, text)
            else:
                text = pattern.sub(replacement, text)
        
        return text
    
    def _apply_special_rules(self, text: str) -> str:
        """Apply special measure theory-specific rules"""
        
        # Emphasize important theorems
        if self.special_rules['emphasize_theorems']:
            theorem_patterns = [
                (r'Monotone Convergence Theorem', 'the Monotone Convergence Theorem'),
                (r'Dominated Convergence Theorem', 'the Dominated Convergence Theorem'),
                (r'Fatou\'s Lemma', 'Fatou\'s Lemma'),
                (r'Radon-Nikodym Theorem', 'the Radon-Nikodym Theorem'),
                (r'Fubini\'s Theorem', 'Fubini\'s Theorem'),
                (r'Lebesgue Decomposition', 'the Lebesgue Decomposition'),
                (r'Hahn Decomposition', 'the Hahn Decomposition'),
            ]
            
            for pattern, replacement in theorem_patterns:
                text = re.sub(pattern, f"{{EMPHASIS}}{replacement}{{/EMPHASIS}}", text, flags=re.IGNORECASE)
        
        # Clarify measure notation when context is unclear
        if self.special_rules['clarify_measures'] and self.context == MeasureTheoryContext.MEASURES:
            # Add clarifications for potentially ambiguous measure notation
            text = re.sub(r'\\mu(?!\\()', 'the measure mu', text)
            text = re.sub(r'\\nu(?!\\()', 'the measure nu', text)
        
        return text
    
    def _postprocess(self, text: str) -> str:
        """Post-process for natural speech"""
        # Fix any double articles
        text = re.sub(r'\bthe\s+the\b', 'the', text)
        text = re.sub(r'\ba\s+a\b', 'a', text)
        text = re.sub(r'\ba\s+an\b', 'an', text)
        text = re.sub(r'\ban\s+a\b', 'a', text)
        
        # Improve flow
        text = re.sub(r'\s+,\s+', ', ', text)
        text = re.sub(r'\s+\.\s+', '. ', text)
        
        # Handle emphasis markers
        text = re.sub(r'\{\{EMPHASIS\}\}', '', text)
        text = re.sub(r'\{\{/EMPHASIS\}\}', '', text)
        
        return text
    
    def get_context_info(self) -> Dict[str, Any]:
        """Get information about current processing context"""
        return {
            'domain': 'measure_theory',
            'subcontext': self.context.value,
            'vocabulary_size': len(self.vocabulary.terms),
            'pattern_count': len(self.vocabulary.patterns),
        }

# ===========================
# Testing Functions
# ===========================

def test_measure_theory_processor():
    """Comprehensive test of measure theory processor"""
    processor = MeasureTheoryProcessor()
    
    test_cases = [
        # Sigma-algebras
        r"Let $\mathcal{A}$ be a $\sigma$-algebra on $X$. Then $\mathcal{A}$ contains $\emptyset$ and $X$.",
        r"The Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R})$ is generated by the open sets.",
        r"If $f: X \to Y$ is measurable, then $f^{-1}(B) \in \mathcal{A}$ for all $B \in \mathcal{B}$.",
        
        # Measures
        r"A measure $\mu$ on $(X, \mathcal{A})$ satisfies $\mu(\emptyset) = 0$ and countable additivity.",
        r"The Lebesgue measure $\lambda$ on $\mathbb{R}$ is translation-invariant.",
        r"If $\mu \ll \nu$, then $\mu$ is absolutely continuous with respect to $\nu$.",
        
        # Integration
        r"The Lebesgue integral of a simple function $s = \sum_{i=1}^n a_i \mathbf{1}_{A_i}$ is $\int s \, d\mu = \sum_{i=1}^n a_i \mu(A_i)$.",
        r"For non-negative measurable $f$, $\int f \, d\mu = \sup\{\int s \, d\mu : s \leq f, s \text{ simple}\}$.",
        r"If $f$ is integrable, then $\int f \, d\mu = \int f^+ \, d\mu - \int f^- \, d\mu$.",
        
        # Convergence theorems
        r"By the Monotone Convergence Theorem, if $0 \leq f_n \uparrow f$, then $\int f_n \, d\mu \uparrow \int f \, d\mu$.",
        r"The Dominated Convergence Theorem: if $|f_n| \leq g$ and $f_n \to f$ a.e., then $\int f_n \, d\mu \to \int f \, d\mu$.",
        r"Fatou's Lemma states that $\liminf \int f_n \, d\mu \geq \int \liminf f_n \, d\mu$.",
        
        # Lp spaces
        r"The space $L^p(X, \mu)$ consists of functions $f$ with $\|f\|_p = \left(\int |f|^p \, d\mu\right)^{1/p} < \infty$.",
        r"For $f \in L^\infty$, $\|f\|_\infty = \text{esssup} |f|$.",
        r"By Hölder's inequality, $\|fg\|_1 \leq \|f\|_p \|g\|_q$ where $1/p + 1/q = 1$.",
        
        # Product measures
        r"Fubini's theorem: if $f \geq 0$ or $f \in L^1(\mu \times \nu)$, then $\int f \, d(\mu \times \nu) = \int \int f(x,y) \, d\mu(x) \, d\nu(y)$.",
        r"Tonelli's theorem applies to non-negative measurable functions.",
        
        # Radon-Nikodym
        r"The Radon-Nikodym theorem: if $\mu \ll \nu$ and $\nu$ is $\sigma$-finite, then $d\mu = h \, d\nu$ for some $h$.",
        r"The density $\frac{d\mu}{d\nu}$ is the Radon-Nikodym derivative of $\mu$ with respect to $\nu$.",
        
        # Advanced topics
        r"The Hardy-Littlewood maximal function $Mf(x) = \sup_{r>0} \frac{1}{|B(x,r)|} \int_{B(x,r)} |f(y)| \, dy$.",
        r"A signed measure has the Jordan decomposition $\mu = \mu^+ - \mu^-$.",
    ]
    
    print("Testing Measure Theory Processor")
    print("=" * 70)
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nTest {i}:")
        print(f"Input:  {test}")
        result = processor.process(test)
        print(f"Output: {result}")
        print(f"Context: {processor.context.value}")
    
    print("\nContext Info:")
    print(processor.get_context_info())

if __name__ == "__main__":
    test_measure_theory_processor()